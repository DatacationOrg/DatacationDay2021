{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the Datacation Bootcamp!\n",
    "\n",
    "Today, we present a coding challenge to you.\n",
    "In this challenge, you will be given two brain tumor dataset. A train and a test dataset.\n",
    "The target variable has been removed from the test dataset. You will try different Machine Learning models and\n",
    "use your best model to predict whether patients have a brain tumor or not.\n",
    "\n",
    "Try to get as far as possible in the following exercises, increasing in difficulty:\n",
    "\n",
    "1. Loading the training set train_brain.csv and split the training set in a training and validation set, then preprocess the data. Options include:\n",
    "    - imputing missing values\n",
    "    - one-hot-encoding categorical values\n",
    "    - scaling the data\n",
    "2. Implement the machine learning model called the Support Vector Machine (SVM) and optimize based on the validation accuracy.\n",
    "3. Visualize the SVM accuracy results in a graph.\n",
    "4. Use a grid search to find the optimal hyperparameters of the SVM, KNN and RandomForest models using 3-fold cross validation.\n",
    "5. Visualize the SVM, KNN and RandomForest accuracy results in a heatmap.\n",
    "6. Implement a Neural Network and visualize the loss and accuracy, both for the test and training dataset.\n",
    "7. Apply any type of model and preprocessing steps necessary to achieve the highest possible validation accuracy.\n",
    "8. Use the test_brain.csv dataset to predict whether the patients have a brain tumor or not. The target variable has been removed from the dataset.\n",
    "   Save the prediction results in a list with the same order as the patients in the test dataset.\n",
    "   Use the given code to store the list as .pkl file and save it using your group number.\n",
    "   Finally, do a push request to the github repository. We will calculate your final accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 1   ######################################\n",
    "'''\n",
    "Loading the training set train_brain.csv and split the training set in a training and validation set, then preprocess the data. Options include:\n",
    "    - imputing missing values\n",
    "    - one-hot-encoding categorical values\n",
    "    - scaling the data\n",
    "'''\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Read in the dataset: (https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    "train = pd.read_csv(\"train_brain.csv\")\n",
    "test = pd.read_csv(\"test_brain.csv\")\n",
    "# Split the training set in a train and validation set, use random_state = 0: (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "train_split,validation = train_test_split(train, test_size=0.3, random_state=0)\n",
    "\n",
    "# Impute missing values: (https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "imp_mean = SimpleImputer(missing_values=np.nan,strategy='most_frequent')\n",
    "imp_mean.fit(train_split)\n",
    "train_imputed = imp_mean.transform(train_split)\n",
    "\n",
    "imp_mean.fit(validation)\n",
    "vali_imputed = imp_mean.transform(validation)\n",
    "\n",
    "# Scale numerical columns: (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "transpose_1 = train_imputed.transpose()\n",
    "transpose_2 = vali_imputed.transpose()\n",
    "transpose = transpose_1\n",
    "\n",
    "for i,column in enumerate(transpose):\n",
    "    if not isinstance(column[0], str):\n",
    "        array = column.reshape(-1, 1)\n",
    "        scaler.fit(array)\n",
    "        array= scaler.transform(array)\n",
    "        transpose[i] = array.reshape(-1)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "train_scaled = transpose.transpose()\n",
    "#vali_scaled = transpose.transpose()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values: (https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "cols = train.columns\n",
    "datatypes = train.dtypes\n",
    "\n",
    "train_df = pd.DataFrame(train_scaled, columns=cols)\n",
    "vali_df =pd.DataFrame(vali_scaled, columns=cols)\n",
    "\n",
    "# First cast all columns that are not 'object's to numeric columns,\n",
    "#   then normalize all numeric columns (manually implemented)\n",
    "for i in range(len(cols)):\n",
    "    if datatypes[i] != 'O':\n",
    "        train_df[cols[i]] = train_df[cols[i]].astype(datatypes[i])\n",
    "        vali_df[cols[i]] = vali_df[cols[i]].astype(datatypes[i])\n",
    "        #train_df[cols[i]] = (train_df[cols[i]] - train_df[cols[i]].mean()) / train_df[cols[i]].std()\n",
    "        \n",
    "# Encode categorical columns to one-hot encoding style\n",
    "train_onehot = pd.get_dummies(train_df)\n",
    "vali_onehot = pd.get_dummies(vali_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>96_Q</th>\n",
       "      <th>96_R</th>\n",
       "      <th>96_S</th>\n",
       "      <th>96_T</th>\n",
       "      <th>96_U</th>\n",
       "      <th>96_V</th>\n",
       "      <th>96_W</th>\n",
       "      <th>96_X</th>\n",
       "      <th>96_Y</th>\n",
       "      <th>96_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>0.495877</td>\n",
       "      <td>-0.509877</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-0.416755</td>\n",
       "      <td>-0.883957</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.392942</td>\n",
       "      <td>-1.548836</td>\n",
       "      <td>-2.360166</td>\n",
       "      <td>-0.686210</td>\n",
       "      <td>-0.512330</td>\n",
       "      <td>-1.378592</td>\n",
       "      <td>-0.827800</td>\n",
       "      <td>1.021800</td>\n",
       "      <td>-0.491925</td>\n",
       "      <td>1.485551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>1.238357</td>\n",
       "      <td>0.842654</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.341709</td>\n",
       "      <td>-1.062458</td>\n",
       "      <td>-1.689021</td>\n",
       "      <td>-0.655218</td>\n",
       "      <td>1.054341</td>\n",
       "      <td>-1.728540</td>\n",
       "      <td>0.316132</td>\n",
       "      <td>3.295645</td>\n",
       "      <td>2.635402</td>\n",
       "      <td>4.165475</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33876</th>\n",
       "      <td>0.834978</td>\n",
       "      <td>0.354109</td>\n",
       "      <td>0.735307</td>\n",
       "      <td>0.587800</td>\n",
       "      <td>0.183637</td>\n",
       "      <td>-1.526542</td>\n",
       "      <td>0.373999</td>\n",
       "      <td>-0.602375</td>\n",
       "      <td>-0.633870</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33877</th>\n",
       "      <td>0.382469</td>\n",
       "      <td>1.841819</td>\n",
       "      <td>0.108445</td>\n",
       "      <td>-0.198922</td>\n",
       "      <td>0.470824</td>\n",
       "      <td>-0.340837</td>\n",
       "      <td>0.444170</td>\n",
       "      <td>-0.416755</td>\n",
       "      <td>-0.201483</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33878</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-1.252044</td>\n",
       "      <td>-0.918103</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33879</th>\n",
       "      <td>0.586232</td>\n",
       "      <td>-0.912161</td>\n",
       "      <td>-0.507078</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>0.701337</td>\n",
       "      <td>1.185910</td>\n",
       "      <td>-0.265716</td>\n",
       "      <td>1.423977</td>\n",
       "      <td>1.830150</td>\n",
       "      <td>-0.259416</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33880</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>0.495877</td>\n",
       "      <td>-0.712761</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33881 rows Ã— 10655 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         4         5         6         7         8  \\\n",
       "0     -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "1     -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "2      2.392942 -1.548836 -2.360166 -0.686210 -0.512330 -1.378592 -0.827800   \n",
       "3     -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "4      0.341709 -1.062458 -1.689021 -0.655218  1.054341 -1.728540  0.316132   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "33876  0.834978  0.354109  0.735307  0.587800  0.183637 -1.526542  0.373999   \n",
       "33877  0.382469  1.841819  0.108445 -0.198922  0.470824 -0.340837  0.444170   \n",
       "33878 -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "33879  0.586232 -0.912161 -0.507078  0.133900  0.701337  1.185910 -0.265716   \n",
       "33880 -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "\n",
       "              9        10        11  ...  96_Q  96_R  96_S  96_T  96_U  96_V  \\\n",
       "0      0.495877 -0.509877 -0.520637  ...     0     0     0     0     0     0   \n",
       "1     -0.416755 -0.883957 -0.520637  ...     0     0     0     0     0     0   \n",
       "2      1.021800 -0.491925  1.485551  ...     0     0     0     0     0     0   \n",
       "3      1.238357  0.842654 -0.520637  ...     0     0     0     0     0     0   \n",
       "4      3.295645  2.635402  4.165475  ...     0     0     0     0     0     0   \n",
       "...         ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "33876 -0.602375 -0.633870  0.408800  ...     0     0     0     0     0     0   \n",
       "33877 -0.416755 -0.201483  0.681515  ...     0     0     0     0     0     0   \n",
       "33878 -1.252044 -0.918103 -0.520637  ...     0     1     0     0     0     0   \n",
       "33879  1.423977  1.830150 -0.259416  ...     0     0     0     0     0     0   \n",
       "33880  0.495877 -0.712761 -0.520637  ...     0     0     0     0     0     0   \n",
       "\n",
       "       96_W  96_X  96_Y  96_Z  \n",
       "0         0     0     0     0  \n",
       "1         0     0     0     0  \n",
       "2         0     0     0     0  \n",
       "3         0     0     0     0  \n",
       "4         0     0     0     0  \n",
       "...     ...   ...   ...   ...  \n",
       "33876     0     0     0     0  \n",
       "33877     0     0     0     1  \n",
       "33878     0     0     0     0  \n",
       "33879     0     0     0     0  \n",
       "33880     0     0     0     0  \n",
       "\n",
       "[33881 rows x 10655 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 2   ######################################\n",
    "'''\n",
    "Implement the machine learning model called the Support Vector Machine (SVM) and optimize based on the validation accuracy.\n",
    "'''\n",
    "\n",
    "# Implement the Support Vector Machine: (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "X_train = train_onehot.drop('target', axis=1)\n",
    "y_train = train_onehot['target']\n",
    "X_vali = vali_onehot.drop('target', axis=1)\n",
    "y_vali = vali_onehot['target']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_vali)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      object\n",
       "1      object\n",
       "2      object\n",
       "3      object\n",
       "4      object\n",
       "        ...  \n",
       "97     object\n",
       "98     object\n",
       "99     object\n",
       "100    object\n",
       "101    object\n",
       "Length: 102, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.get_dummies(train_df)\n",
    "vali_df = pd.get_dummies(vali_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = pd.get_dummies(train_scaled)\n",
    "\n",
    "transpose_1 = train_imputed.transpose()\n",
    "transpose_2 = vali_imputed.transpose()\n",
    "transpose = transpose_1\n",
    "\n",
    "for i,column in enumerate(transpose):\n",
    "    if not isinstance(column[0], str):\n",
    "        array = column.reshape(-1, 1)\n",
    "        scaler.fit(array)\n",
    "        array= scaler.transform(array)\n",
    "        transpose[i] = array.reshape(-1)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "train_scaled = transpose.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 3   ######################################\n",
    "'''\n",
    "Visualize the SVM accuracy results in a graph.\n",
    "'''\n",
    "\n",
    "# Visualize the SVM results: (https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 4   ######################################\n",
    "'''\n",
    "Use a grid search to find the optimal hyperparameters of the SVM, KNN and RandomForest models using 3-fold cross validation.\n",
    "'''\n",
    "\n",
    "# Make use of GridSearchCV: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# KNN: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "# RandomForest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 5   ######################################\n",
    "'''\n",
    "Visualize the SVM, KNN and RandomForest accuracy results in a heatmap.\n",
    "'''\n",
    "\n",
    "# Make us of a heatmap: https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 6   ######################################\n",
    "'''\n",
    "Implement a basic Neural Network and visualize the loss and accuracy, both for the test and training dataset.\n",
    "'''\n",
    "\n",
    "# Make use of the MLPClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 7   ######################################\n",
    "'''\n",
    "Apply any type of model and preprocessing steps necessary to achieve the highest possible validation accuracy.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 8   ######################################\n",
    "'''\n",
    "Time to predict using your best ML model!\n",
    "Use the test_brain.csv dataset to predict whether the patients have a brain tumor or not. The target variable has been removed from the dataset.\n",
    "Save the prediction results in a list with the same order as the patients in the test dataset.\n",
    "Use the below given code to store the list as .pkl file and save it using your group number.\n",
    "Finally, do a push request to the github repository. We will calculate your final accuracy score.\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "group_number = 0\n",
    "ypred = []\n",
    "\n",
    "with open(f'test_predictions_group_{group_number}.pkl', 'wb') as f:\n",
    "    pickle.dump(ypred, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
